{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import yaml\n",
    "from langdetect import detect\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from modules.data import DFATokenizer, get_mask_from_batch\n",
    "from utils.aligner.cleaners import english_cleaners, nonenglish_cleaners, nonenglish_cleaners_no_transliteration\n",
    "from inference import LitParrot\n",
    "from utils.vocoder.utils import AttrDict\n",
    "from utils.vocoder.models import CodeGenerator\n",
    "from utils.vocoder.dataset import MAX_WAV_VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide whether to download `transliterad` / `no_transliterated` models. `no_transliterated` means non-English characters are used as it is without being transliterated to English characters.\n",
    "\n",
    "We would recommend switching `transliteration` to False for non-English languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliteration=False # if False, runs ParrotTTS using on original non-English characters. if True, runs ParrotTTS using non-English characters transliterated to English characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download symbol and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading models trained using non-transliterated (as it is) characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1seuLFK_xYyqyYXAsHGjvGlMiqnwHa54G\n",
      "To: /media/newhd/Neil/Parrot-TTS/runs/aligner/symbols.pkl\n",
      "100%|██████████| 1.72k/1.72k [00:00<00:00, 1.02MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1RUX3ZTHXGW5Ke6r7fwWMykN2bOGpVsss\n",
      "From (redirected): https://drive.google.com/uc?id=1RUX3ZTHXGW5Ke6r7fwWMykN2bOGpVsss&confirm=t&uuid=d95dfd56-767d-4fe0-b83e-1de80f4aaa14\n",
      "To: /media/newhd/Neil/Parrot-TTS/runs/TTE/ckpt/parrot_model-step=11000-val_total_loss_step=0.00.ckpt\n",
      "100%|██████████| 315M/315M [00:56<00:00, 5.57MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1k73yYtfHM2SN9x-g2c0Ep8QmamtnceJE\n",
      "To: /media/newhd/Neil/Parrot-TTS/runs/TTE/speakers.json\n",
      "100%|██████████| 112/112 [00:00<00:00, 242kB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1PTk42aTOKn6P7FgBmReXWdGj4hSz0NN8\n",
      "From (redirected): https://drive.google.com/uc?id=1PTk42aTOKn6P7FgBmReXWdGj4hSz0NN8&confirm=t&uuid=03045088-37fc-4be4-b00d-7da43429de73\n",
      "To: /media/newhd/Neil/Parrot-TTS/runs/vocoder/checkpoints/g_00750000\n",
      "100%|██████████| 55.5M/55.5M [00:09<00:00, 5.74MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/vocoder/checkpoints/g_00750000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "symbols_path = \"runs/aligner/symbols.pkl\"\n",
    "TTE_checkpoint = \"runs/TTE/ckpt/parrot_model-step=11000-val_total_loss_step=0.00.ckpt\"\n",
    "speaker_json_path = \"runs/TTE/speakers.json\"\n",
    "\n",
    "vocoder_checkpoint = \"runs/vocoder/checkpoints/g_00750000\"\n",
    "store_processed_audio_path = \"runs/vocoder/generations_tte\"\n",
    "\n",
    "if not os.path.exists(store_processed_audio_path):\n",
    "    os.makedirs(store_processed_audio_path)\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "for path in [\"runs/aligner\", \"runs/TTE/ckpt\", \"runs/vocoder/checkpoints\"]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Google Drive direct download link\n",
    "if transliteration:\n",
    "    \n",
    "    print(\"Downloading models trained using transliterated characters\")\n",
    "\n",
    "    # Download symbols.pkl having just English characters\n",
    "    file_id = \"1D-RXBf_n1pQlJ5gvsGjjVPkDX1Ps6igp\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, symbols_path, quiet=False)\n",
    "\n",
    "    # Download TTE checkpoint that maps characters to HuBERT units\n",
    "    file_id = \"1YCILO6lRqiB9_Po-vbeJKZ-G_UxOEEgD\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, TTE_checkpoint, quiet=False)\n",
    "\n",
    "    # Download speaker ID mapper\n",
    "    file_id = \"1KiTYQGPPXbOgXEdw4ka6YMoyEcpFiy9p\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, speaker_json_path, quiet=False)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Downloading models trained using non-transliterated (as it is) characters\")\n",
    "\n",
    "    # Download symbols.pkl having both English and original non-English characters\n",
    "    file_id = \"1seuLFK_xYyqyYXAsHGjvGlMiqnwHa54G\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, symbols_path, quiet=False)\n",
    "\n",
    "    # Download TTE checkpoint that maps characters to HuBERT units\n",
    "    file_id = \"1RUX3ZTHXGW5Ke6r7fwWMykN2bOGpVsss\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, TTE_checkpoint, quiet=False)\n",
    "\n",
    "    # Download speaker ID mapper\n",
    "    file_id = \"1k73yYtfHM2SN9x-g2c0Ep8QmamtnceJE\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, speaker_json_path, quiet=False)\n",
    "\n",
    "# Download Hifi-GAN vocoder checkpoint trained on 10 speakers and 5 languages (English, Hindi, Gujarati, Bhojpuri, Kannada)\n",
    "file_id = \"1PTk42aTOKn6P7FgBmReXWdGj4hSz0NN8\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, vocoder_checkpoint, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() and 'cuda' in 'cuda:2' else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_to_idx: {' ': 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'C': 7, 'D': 8, 'E': 9, 'H': 10, 'I': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'Y': 22, 'Z': 23, 'a': 24, 'b': 25, 'c': 26, 'd': 27, 'e': 28, 'f': 29, 'g': 30, 'h': 31, 'i': 32, 'j': 33, 'k': 34, 'l': 35, 'm': 36, 'n': 37, 'o': 38, 'p': 39, 'q': 40, 'r': 41, 's': 42, 't': 43, 'u': 44, 'v': 45, 'w': 46, 'x': 47, 'y': 48, 'z': 49, '°': 50, '·': 51, 'º': 52, '½': 53, 'â': 54, 'ʼ': 55, 'ँ': 56, 'ं': 57, 'ः': 58, 'अ': 59, 'आ': 60, 'इ': 61, 'ई': 62, 'उ': 63, 'ऊ': 64, 'ऋ': 65, 'ऍ': 66, 'ऎ': 67, 'ए': 68, 'ऐ': 69, 'ऑ': 70, 'ऒ': 71, 'ओ': 72, 'औ': 73, 'क': 74, 'ख': 75, 'ग': 76, 'घ': 77, 'ङ': 78, 'च': 79, 'छ': 80, 'ज': 81, 'झ': 82, 'ञ': 83, 'ट': 84, 'ठ': 85, 'ड': 86, 'ढ': 87, 'ण': 88, 'त': 89, 'थ': 90, 'द': 91, 'ध': 92, 'न': 93, 'ऩ': 94, 'प': 95, 'फ': 96, 'ब': 97, 'भ': 98, 'म': 99, 'य': 100, 'र': 101, 'ऱ': 102, 'ल': 103, 'ळ': 104, 'व': 105, 'श': 106, 'ष': 107, 'स': 108, 'ह': 109, 'ऺ': 110, '़': 111, 'ऽ': 112, 'ा': 113, 'ि': 114, 'ी': 115, 'ु': 116, 'ू': 117, 'ृ': 118, 'ॄ': 119, 'ॅ': 120, 'ॆ': 121, 'े': 122, 'ै': 123, 'ॉ': 124, 'ॊ': 125, 'ो': 126, 'ौ': 127, '्': 128, 'ॐ': 129, 'ॕ': 130, 'ॖ': 131, 'क़': 132, 'ख़': 133, 'ग़': 134, 'ज़': 135, 'ड़': 136, 'ढ़': 137, 'फ़': 138, 'य़': 139, 'ॠ': 140, '।': 141, '॥': 142, '॰': 143, 'ॲ': 144, 'ઁ': 145, 'ં': 146, 'ઃ': 147, 'અ': 148, 'આ': 149, 'ઇ': 150, 'ઈ': 151, 'ઉ': 152, 'ઊ': 153, 'ઋ': 154, 'ઍ': 155, 'એ': 156, 'ઐ': 157, 'ઑ': 158, 'ઓ': 159, 'ઔ': 160, 'ક': 161, 'ખ': 162, 'ગ': 163, 'ઘ': 164, 'ચ': 165, 'છ': 166, 'જ': 167, 'ઝ': 168, 'ઞ': 169, 'ટ': 170, 'ઠ': 171, 'ડ': 172, 'ઢ': 173, 'ણ': 174, 'ત': 175, 'થ': 176, 'દ': 177, 'ધ': 178, 'ન': 179, 'પ': 180, 'ફ': 181, 'બ': 182, 'ભ': 183, 'મ': 184, 'ય': 185, 'ર': 186, 'લ': 187, 'ળ': 188, 'વ': 189, 'શ': 190, 'ષ': 191, 'સ': 192, 'હ': 193, '઼': 194, 'ા': 195, 'િ': 196, 'ી': 197, 'ુ': 198, 'ૂ': 199, 'ૃ': 200, 'ૅ': 201, 'ે': 202, 'ૈ': 203, 'ૉ': 204, 'ો': 205, 'ૌ': 206, '્': 207, 'ૠ': 208, '૦': 209, '૧': 210, '૨': 211, '૩': 212, '૪': 213, '૫': 214, '૬': 215, '૭': 216, '૮': 217, '૯': 218, 'ಂ': 219, 'ಃ': 220, 'ಅ': 221, 'ಆ': 222, 'ಇ': 223, 'ಈ': 224, 'ಉ': 225, 'ಊ': 226, 'ಋ': 227, 'ಎ': 228, 'ಏ': 229, 'ಐ': 230, 'ಒ': 231, 'ಓ': 232, 'ಔ': 233, 'ಕ': 234, 'ಖ': 235, 'ಗ': 236, 'ಘ': 237, 'ಙ': 238, 'ಚ': 239, 'ಛ': 240, 'ಜ': 241, 'ಝ': 242, 'ಞ': 243, 'ಟ': 244, 'ಠ': 245, 'ಡ': 246, 'ಢ': 247, 'ಣ': 248, 'ತ': 249, 'ಥ': 250, 'ದ': 251, 'ಧ': 252, 'ನ': 253, 'ಪ': 254, 'ಫ': 255, 'ಬ': 256, 'ಭ': 257, 'ಮ': 258, 'ಯ': 259, 'ರ': 260, 'ಱ': 261, 'ಲ': 262, 'ಳ': 263, 'ವ': 264, 'ಶ': 265, 'ಷ': 266, 'ಸ': 267, 'ಹ': 268, '಼': 269, 'ಽ': 270, 'ಾ': 271, 'ಿ': 272, 'ೀ': 273, 'ು': 274, 'ೂ': 275, 'ೃ': 276, 'ೆ': 277, 'ೇ': 278, 'ೈ': 279, 'ೊ': 280, 'ೋ': 281, 'ೌ': 282, '್': 283, 'ೕ': 284, 'ೖ': 285, 'ೠ': 286, '೦': 287, '೧': 288, '೨': 289, '೩': 290, '೪': 291, '೫': 292, '೬': 293, '೭': 294, '೮': 295, '೯': 296, '\\u200b': 297, '\\u200c': 298, '\\u200d': 299, '\\u200e': 300, '•': 301}\n"
     ]
    }
   ],
   "source": [
    "with open(symbols_path, \"rb\") as f: \n",
    "    symbols = pickle.load(f)\n",
    "idx_to_token = {i: s for i, s in enumerate(symbols, start=1)}\n",
    "token_to_idx = {s: i for i, s in idx_to_token.items()}\n",
    "print(f\"token_to_idx: {token_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a text to be converted to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: ['इ', 'स', 'क', 'े', 'sil', 'ल', 'ि', 'ए', 'sil', 'स', 'ं', 'र', 'क', '्', 'ष', 'ि', 'त', 'sil', 'ख', 'े', 'त', 'ी', ',', 'sil', 'म', 'ध', 'ु', 'म', 'क', '्', 'ख', 'ी', 'sil', 'प', 'ा', 'ल', 'न', 'sil', 'इ', 'त', '्', 'य', 'ा', 'द', 'ि', 'sil', 'प', 'र', 'sil', 'अ', 'ग', 'ल', 'े', 'sil', 'प', 'ं', 'च', 'व', 'र', '्', 'ष', 'ी', 'य', 'sil', 'य', 'ो', 'ज', 'न', 'ा', 'sil', 'म', 'े', 'ं', 'sil', 'म', 'ह', 'त', '्', 'त', '्', 'व', 'sil', 'द', 'े', 'न', 'ा', 'sil', 'ह', 'ो', 'ग', 'ा']\n"
     ]
    }
   ],
   "source": [
    "text = \"इसके लिए संरक्षित खेती, मधुमक्खी पालन इत्यादि पर अगले पंचवर्षीय योजना में महत्त्व देना होगा\"\n",
    "\n",
    "# Perform text cleaning\n",
    "if detect(text) == 'en':\n",
    "    use_englishcleaners = True\n",
    "else:\n",
    "    use_englishcleaners = False\n",
    "\n",
    "cleaners = english_cleaners if use_englishcleaners else nonenglish_cleaners_no_transliteration if not transliteration else nonenglish_cleaners\n",
    "cleaned_text = cleaners(text)\n",
    "\n",
    "# convert text into characters\n",
    "characters = [c for c in cleaned_text if c in token_to_idx]\n",
    "characters = ['sil' if char == ' ' else char for char in characters]\n",
    "print(f\"characters: {characters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TTE module: Predict HuBERT codes from input characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/anaconda3/envs/parrottts/lib/python3.8/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "data_config = yaml.load(open(\"utils/TTE/TTE_config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# init the model\n",
    "model = LitParrot.load_from_checkpoint(TTE_checkpoint,weights_only=True)\n",
    "\n",
    "# Move model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DFATokenizer(Path(data_config[\"path\"][\"alignment_path\"]))\n",
    "\n",
    "# Manually pad sequences and create data dictionary\n",
    "data = {\n",
    "    'ids': 'random',\n",
    "    'speaker': torch.tensor([0], dtype=torch.long),\n",
    "    'phones': torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(tokenizer.tokenize(\" \".join(characters).split(' ')), dtype=torch.long)], batch_first=True, padding_value=tokenizer.pad_idx\n",
    "    ),\n",
    "    'codes': torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor([int(i) for i in '1'.split(' ')], dtype=torch.long)], batch_first=True, padding_value=data_config[\"preprocess\"][\"hubert_codes\"]\n",
    "    ),\n",
    "    'duration': torch.nn.utils.rnn.pad_sequence([torch.tensor([int(i) for i in '1'.split(' ')], dtype=torch.long)], batch_first=True),\n",
    "    'src_mask': get_mask_from_batch(torch.nn.utils.rnn.pad_sequence([torch.tensor(tokenizer.tokenize(\" \".join(characters).split(' ')), dtype=torch.long)], \n",
    "                                                                    batch_first=True, padding_value=tokenizer.pad_idx), tokenizer.pad_idx)\n",
    "}\n",
    "\n",
    "# Infer using TTE model\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    # Move batch to the same device as the model\n",
    "    batch = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in data.items()}\n",
    "    \n",
    "    # Perform inference\n",
    "    codes = ' '.join(map(str, model.infer(batch)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vocoder module: generate speech from predicted HuBERT codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/anaconda3/envs/parrottts/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/tmp/ipykernel_351545/1807678079.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict_g = torch.load(vocoder_checkpoint, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audios at runs/vocoder/generations_tte\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "config_file = \"utils/vocoder/config.json\"\n",
    "with open(config_file) as f:\n",
    "    data = f.read()\n",
    "json_config = json.loads(data)\n",
    "h = AttrDict(json_config)\n",
    "\n",
    "# load checkpoint\n",
    "generator = CodeGenerator(h).to(device)\n",
    "state_dict_g = torch.load(vocoder_checkpoint, map_location=device)\n",
    "generator.load_state_dict(state_dict_g['generator'])\n",
    "generator.to(device)\n",
    "\n",
    "# Preprocess codes\n",
    "result = {\n",
    "    'code': torch.tensor(np.array([int(num) for num in codes.split()])).unsqueeze(0).to(device),\n",
    "    'spkr': torch.tensor([0]).unsqueeze(0).to(device)  # Shape: (1,)\n",
    "}\n",
    "\n",
    "spkr_to_id = {'bho_f': 0, 'bho_m': 1, 'en_f': 2, 'en_m': 3, 'gu_f': 4, 'gu_m': 5, 'hi_f': 6, 'hi_m': 7, 'kn_f': 8, 'kn_m': 9}\n",
    "local_spkrs = list(spkr_to_id.values())\n",
    "\n",
    "def generate(codess):\n",
    "    y_g_hat = generator(**codess)\n",
    "    if type(y_g_hat) is tuple:\n",
    "        y_g_hat = y_g_hat[0]\n",
    "    audio = y_g_hat.squeeze()\n",
    "    audio = audio * MAX_WAV_VALUE\n",
    "    audio = audio.detach().cpu().numpy().astype('int16')\n",
    "    return audio\n",
    "\n",
    "print(f\"Generating audios at {store_processed_audio_path}\")\n",
    "\n",
    "for spkr_i, k in enumerate(local_spkrs):\n",
    "    result['spkr'] = torch.tensor([k]).unsqueeze(0).to(device)\n",
    "    audio = generate(result)\n",
    "\n",
    "    key_found = next((key for key, value in spkr_to_id.items() if value == k), None)\n",
    "    output_file = os.path.join(store_processed_audio_path  + f'/result_{key_found}_gen.wav')\n",
    "    audio = librosa.util.normalize(audio.astype(np.float32))\n",
    "    write(output_file, h.sampling_rate, audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parrottts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
