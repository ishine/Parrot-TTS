{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from langdetect import detect\n",
    "import lightning as L\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from modules.data import DFATokenizer, get_mask_from_batch\n",
    "from utils.aligner.cleaners import english_cleaners, nonenglish_cleaners\n",
    "from inference import LitParrot\n",
    "from utils.vocoder.utils import AttrDict\n",
    "from utils.vocoder.models import CodeGenerator\n",
    "from utils.vocoder.dataset import MAX_WAV_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoints and symbol pickle files trained on Limmits data\n",
    "symbols_path = \"runs/aligner/symbols.pkl\"\n",
    "TTE_checkpoint = \"runs/TTE/ckpt/parrot_model-step=11000-val_total_loss_step=0.00.ckpt\"\n",
    "vocoder_checkpoint = \"runs/vocoder/checkpoints/g_00750000\"\n",
    "speaker_json_path = \"runs/TTE/speakers.json\"\n",
    "\n",
    "store_processed_audio_path = \"runs/vocoder/generations\"\n",
    "if not os.path.exists(store_processed_audio_path):\n",
    "    os.makedirs(store_processed_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories if they don't exist\n",
    "for path in [\"runs/aligner\", \"runs/TTE/ckpt\", \"runs/vocoder/checkpoints\"]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Google Drive direct download link\n",
    "file_id = \"1D-RXBf_n1pQlJ5gvsGjjVPkDX1Ps6igp\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, symbols_path, quiet=False)\n",
    "\n",
    "file_id = \"1PTk42aTOKn6P7FgBmReXWdGj4hSz0NN8\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, vocoder_checkpoint, quiet=False)\n",
    "\n",
    "file_id = \"1YCILO6lRqiB9_Po-vbeJKZ-G_UxOEEgD\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, TTE_checkpoint, quiet=False)\n",
    "\n",
    "file_id = \"1KiTYQGPPXbOgXEdw4ka6YMoyEcpFiy9p\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, speaker_json_path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() and 'cuda' in 'cuda:2' else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(symbols_path, \"rb\") as f: \n",
    "    symbols = pickle.load(f)\n",
    "idx_to_token = {i: s for i, s in enumerate(symbols, start=1)}\n",
    "token_to_idx = {s: i for i, s in idx_to_token.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a text to be converted to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: ['h', 'e', 'l', 'l', 'o', 'sil', 'm', 'y', 'sil', 'n', 'a', 'm', 'e', 'sil', 'i', 's', 'sil', 'p', 'a', 'r', 'r', 'o', 't', 't', 'e', 'x', 't', 'sil', 't', 'o', 'sil', 's', 'p', 'e', 'e', 'c', 'h', 'sil', 't', 'h', 'i', 's', 'sil', 'i', 's', 'sil', 'm', 'y', 'sil', 'r', 'e', 's', 't', 'i', 'n', 'g', 'sil', 'p', 'l', 'a', 'c', 'e', '.', 'sil', 'p', 'l', 'e', 'a', 's', 'e', 'sil', 'f', 'e', 'e', 'l', 'sil', 'f', 'r', 'e', 'e', 'sil', 't', 'o', 'sil', 'i', 'n', 'v', 'o', 'k', 'e', 'sil', 'm', 'e', 'sil', 'a', 't', 'sil', 'y', 'o', 'u', 'r', 'sil', 'c', 'o', 'n', 'v', 'e', 'n', 'i', 'e', 'n', 'c', 'e', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello my name is Parrot-TTS. This is my resting place. Please feel free to invoke me at your convenience.\"\n",
    "\n",
    "# Perform text cleaning\n",
    "if detect(text) == 'en':\n",
    "    use_englishcleaners = True\n",
    "else:\n",
    "    use_englishcleaners = False\n",
    "cleaned_text = english_cleaners(text) if use_englishcleaners else nonenglish_cleaners(text)\n",
    "\n",
    "# convert text into characters\n",
    "characters = [c for c in cleaned_text if c in token_to_idx]\n",
    "characters = ['sil' if char == ' ' else char for char in characters]\n",
    "print(f\"characters: {characters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TTE module: Predict HuBERT codes from input characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/anaconda3/envs/parrottts/lib/python3.8/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "data_config = yaml.load(open(\"utils/TTE/TTE_config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# init the model\n",
    "model = LitParrot.load_from_checkpoint(TTE_checkpoint,weights_only=True)\n",
    "\n",
    "# Move model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DFATokenizer(Path(data_config[\"path\"][\"alignment_path\"]))\n",
    "\n",
    "# Manually pad sequences and create data dictionary\n",
    "data = {\n",
    "    'ids': 'random',\n",
    "    'speaker': torch.tensor([0], dtype=torch.long),\n",
    "    'phones': torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(tokenizer.tokenize(\" \".join(characters).split(' ')), dtype=torch.long)], batch_first=True, padding_value=tokenizer.pad_idx\n",
    "    ),\n",
    "    'codes': torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor([int(i) for i in '1'.split(' ')], dtype=torch.long)], batch_first=True, padding_value=data_config[\"preprocess\"][\"hubert_codes\"]\n",
    "    ),\n",
    "    'duration': torch.nn.utils.rnn.pad_sequence([torch.tensor([int(i) for i in '1'.split(' ')], dtype=torch.long)], batch_first=True),\n",
    "    'src_mask': get_mask_from_batch(torch.nn.utils.rnn.pad_sequence([torch.tensor(tokenizer.tokenize(\" \".join(characters).split(' ')), dtype=torch.long)], \n",
    "                                                                    batch_first=True, padding_value=tokenizer.pad_idx), tokenizer.pad_idx)\n",
    "}\n",
    "\n",
    "# Infer using TTE model\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    # Move batch to the same device as the model\n",
    "    batch = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in data.items()}\n",
    "    \n",
    "    # Perform inference\n",
    "    codes = ' '.join(map(str, model.infer(batch)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vocoder module: generate speech from predicted HuBERT codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32225/3330694324.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict_g = torch.load(vocoder_checkpoint, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "config_file = \"utils/vocoder/config.json\"\n",
    "with open(config_file) as f:\n",
    "    data = f.read()\n",
    "json_config = json.loads(data)\n",
    "h = AttrDict(json_config)\n",
    "\n",
    "# load checkpoint\n",
    "generator = CodeGenerator(h).to(device)\n",
    "state_dict_g = torch.load(vocoder_checkpoint, map_location=device)\n",
    "generator.load_state_dict(state_dict_g['generator'])\n",
    "generator.to(device)\n",
    "\n",
    "# Preprocess codes\n",
    "result = {\n",
    "    'code': torch.tensor(np.array([int(num) for num in codes.split()])).unsqueeze(0).to(device),\n",
    "    'spkr': torch.tensor([0]).unsqueeze(0).to(device)  # Shape: (1,)\n",
    "}\n",
    "\n",
    "spkr_to_id = {'bho_f': 0, 'bho_m': 1, 'en_f': 2, 'en_m': 3, 'gu_f': 4, 'gu_m': 5, 'hi_f': 6, 'hi_m': 7, 'kn_f': 8, 'kn_m': 9}\n",
    "local_spkrs = list(spkr_to_id.values())\n",
    "\n",
    "def generate(codess):\n",
    "    y_g_hat = generator(**codess)\n",
    "    if type(y_g_hat) is tuple:\n",
    "        y_g_hat = y_g_hat[0]\n",
    "    audio = y_g_hat.squeeze()\n",
    "    audio = audio * MAX_WAV_VALUE\n",
    "    audio = audio.detach().cpu().numpy().astype('int16')\n",
    "    return audio\n",
    "\n",
    "print(f\"Generating audios at {store_processed_audio_path}\")\n",
    "\n",
    "for spkr_i, k in enumerate(local_spkrs):\n",
    "    result['spkr'] = torch.tensor([k]).unsqueeze(0).to(device)\n",
    "    audio = generate(result)\n",
    "\n",
    "    key_found = next((key for key, value in spkr_to_id.items() if value == k), None)\n",
    "    output_file = os.path.join(store_processed_audio_path  + f'/result_{key_found}_gen.wav')\n",
    "    audio = librosa.util.normalize(audio.astype(np.float32))\n",
    "    write(output_file, h.sampling_rate, audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parrottts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
