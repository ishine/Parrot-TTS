{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from langdetect import detect\n",
    "import lightning as L\n",
    "from IPython.display import Audio\n",
    "\n",
    "from modules import ParrotDataset, Parrot\n",
    "from utils.aligner.cleaners import english_cleaners, nonenglish_cleaners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() and 'cuda' in 'cuda:2' else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"runs/aligner/symbols.pkl\", \"rb\") as f: \n",
    "    symbols = pickle.load(f)\n",
    "idx_to_token = {i: s for i, s in enumerate(symbols, start=1)}\n",
    "token_to_idx = {s: i for i, s in idx_to_token.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a text to be converted to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello my name is neil. I am standing in a queue. I am currently placed number 20 in a queue.\"\n",
    "\n",
    "# Perform text cleaning\n",
    "if detect(text) == 'en':\n",
    "    use_englishcleaners = True\n",
    "else:\n",
    "    use_englishcleaners = False\n",
    "cleaned_text = english_cleaners(text) if use_englishcleaners else nonenglish_cleaners(text)\n",
    "\n",
    "# convert text into characters\n",
    "characters = [c for c in cleaned_text if c in token_to_idx]\n",
    "characters = ['sil' if char == ' ' else char for char in characters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TTE module: Predict HuBERT codes from input characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "data_config = yaml.load(open(\"utils/TTE/TTE_config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# Model\n",
    "class LitParrot(L.LightningModule):\n",
    "    \n",
    "    # define model architecture\n",
    "    def __init__(\n",
    "        self, data_config, src_vocab_size, src_pad_idx\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.parrot = Parrot(data_config, src_vocab_size, src_pad_idx)\n",
    "    \n",
    "    def infer(self, batch):\n",
    "        self.eval()\n",
    "        res = self.parrot.infer(batch)\n",
    "        return res\n",
    "    \n",
    "# pre-requisites and store at \"runs/TTE/val.txt\"\n",
    "processed_lines = []\n",
    "data_dict = {}\n",
    "data_dict['audio'] = 'random.wav'\n",
    "data_dict['hubert'] = '1 2 3'\n",
    "data_dict['duration'] = \"1 2 3\"\n",
    "data_dict['speaker'] = 'en_m'\n",
    "data_dict['characters'] = \" \".join(characters) \n",
    "processed_lines.append(data_dict)\n",
    "\n",
    "with open(\"runs/TTE/val.txt\", 'w') as f:\n",
    "    for line in processed_lines:\n",
    "        f.write(str(line) + \"\\n\")\n",
    "\n",
    "# initialize dataloader\n",
    "val_dataset = ParrotDataset(\"val\", data_config=data_config)\n",
    "val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        collate_fn=val_dataset.collate_fn,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "# load TTE checkpoint\n",
    "checkpoint = \"runs/TTE/ckpt/parrot_model-step=11000-val_total_loss_step=0.00.ckpt\"\n",
    "\n",
    "# init the model\n",
    "model = LitParrot.load_from_checkpoint(checkpoint,weights_only=True)\n",
    "\n",
    "# Move model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "processed_lines = []\n",
    "batch = next(iter(val_loader))  # Get the single batch from the loader\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    # Move batch to the same device as the model\n",
    "    batch = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in batch.items()}\n",
    "    \n",
    "    # Perform inference\n",
    "    codes = ' '.join(map(str, model.infer(batch)[0]))\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    data_dict = {\n",
    "        'audio': \"random.wav\",\n",
    "        'hubert': codes,\n",
    "        'duration': 0\n",
    "    }\n",
    "\n",
    "    # Append the processed line\n",
    "    processed_lines.append(data_dict)\n",
    "\n",
    "# Save the results to a file\n",
    "with open(\"runs/TTE/predictions.txt\", 'w') as f:\n",
    "    for line in processed_lines:\n",
    "        f.write(str(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vocoder model: Predict speech from the predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/vocoder/inference.py --checkpoint_file runs/vocoder/checkpoints --vc --input_code_file runs/TTE/predictions.txt --output_dir runs/vocoder/generations_tte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted speech is stored at generations_tte\n",
    "# select any audio file available at audio_path\n",
    "audio_path = 'runs/vocoder/generations_tte/random_en_f_gen.wav'\n",
    "Audio(audio_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipvoicer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
